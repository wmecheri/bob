{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab784e78-b249-40ea-8301-5df7657b65ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_from_disk\n",
    "from tqdm.auto import tqdm\n",
    "import gc\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e44db59d-8ef7-4c30-8d4b-f581205c582d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced dataset loaded from disk.\n",
      "Dataset size: 17061 images.\n",
      "Train dataset size: 11942 images\n",
      "Validation dataset size: 1706 images\n",
      "Test dataset size: 3413 images\n",
      "DataLoaders are ready.\n",
      "Number of genre classes: 11\n",
      "Number of style classes: 11\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5133ce7da8a94d2383c2019d49ad4a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1:   0%|          | 0/374 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ad67fff5254f228686d3ba9f5a0c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Epoch 1:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: Train Loss = 4.8234, Genre Acc = 0.1196, Style Acc = 0.1072, Joint Acc = 0.0232\n",
      "                  Val   Loss = 4.7164, Genre Acc = 0.1805, Style Acc = 0.1266, Joint Acc = 0.0492\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8ad7b48178427c9e5bc810ee39c882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 2:   0%|          | 0/374 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e72a5eaaa7440b2a5ccc31fe9befc1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Epoch 2:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10: Train Loss = 4.6358, Genre Acc = 0.1834, Style Acc = 0.1455, Joint Acc = 0.0573\n",
      "                  Val   Loss = 5.0393, Genre Acc = 0.1512, Style Acc = 0.1407, Joint Acc = 0.0340\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33bf4dd639194c4987bbaca02086da75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 3:   0%|          | 0/374 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff42acb1078c4c38b9107e36fb553d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Epoch 3:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: Train Loss = 4.4722, Genre Acc = 0.2315, Style Acc = 0.1802, Joint Acc = 0.0798\n",
      "                  Val   Loss = 4.3873, Genre Acc = 0.2509, Style Acc = 0.2052, Joint Acc = 0.0967\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da7d4c86de604f5f86a4456cc610a4d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 4:   0%|          | 0/374 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2ac19ae6c6423494ee21cd5bc25e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Epoch 4:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: Train Loss = 4.3452, Genre Acc = 0.2663, Style Acc = 0.2118, Joint Acc = 0.0978\n",
      "                  Val   Loss = 4.3175, Genre Acc = 0.2831, Style Acc = 0.2116, Joint Acc = 0.1067\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68e44f6d845441ba2d05d5317420d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 5:   0%|          | 0/374 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e943f19335104800a5f7da23b59938c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Epoch 5:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10: Train Loss = 4.2593, Genre Acc = 0.2809, Style Acc = 0.2249, Joint Acc = 0.1038\n",
      "                  Val   Loss = 4.1856, Genre Acc = 0.3030, Style Acc = 0.2309, Joint Acc = 0.1213\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ba224ee5e44389867c181610b92acc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 6:   0%|          | 0/374 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db7dc5736384dc3b8d748e6d66c7576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Epoch 6:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10: Train Loss = 4.1996, Genre Acc = 0.2949, Style Acc = 0.2356, Joint Acc = 0.1192\n",
      "                  Val   Loss = 4.1416, Genre Acc = 0.3200, Style Acc = 0.2491, Joint Acc = 0.1243\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb62ce43d0e044c1a5e48daf9d34fec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 7:   0%|          | 0/374 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde56762194442b7956879a7487b8261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Epoch 7:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: Train Loss = 4.1446, Genre Acc = 0.3077, Style Acc = 0.2500, Joint Acc = 0.1288\n",
      "                  Val   Loss = 4.1487, Genre Acc = 0.3171, Style Acc = 0.2403, Joint Acc = 0.1325\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e06ed92a5ee04d3fac4e840542212d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 8:   0%|          | 0/374 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74295da16b6b40b989af1697494b657e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Epoch 8:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: Train Loss = 4.1009, Genre Acc = 0.3190, Style Acc = 0.2576, Joint Acc = 0.1332\n",
      "                  Val   Loss = 4.1225, Genre Acc = 0.3165, Style Acc = 0.2567, Joint Acc = 0.1383\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e07d3c1bc444e0853b07ce750b0446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 9:   0%|          | 0/374 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ae54e819a074436995d4e0f807878d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Epoch 9:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: Train Loss = 4.0659, Genre Acc = 0.3232, Style Acc = 0.2695, Joint Acc = 0.1383\n",
      "                  Val   Loss = 4.1141, Genre Acc = 0.3253, Style Acc = 0.2485, Joint Acc = 0.1354\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d476b8f90a90432ba94a4f8200e33101",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 10:   0%|          | 0/374 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc9efe91e8f4c3189e5e82427d10c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation Epoch 10:   0%|          | 0/54 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10: Train Loss = 4.0318, Genre Acc = 0.3312, Style Acc = 0.2783, Joint Acc = 0.1470\n",
      "                  Val   Loss = 3.9897, Genre Acc = 0.3429, Style Acc = 0.2802, Joint Acc = 0.1559\n",
      "Training complete.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ebb7fcd03f4a9a9411b1474979c9d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/107 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss = 4.0067, Genre Acc = 0.3387, Style Acc = 0.2763, Joint Acc = 0.1474\n",
      "Training and testing complete.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"C:/Users/wassi/Documents/Fanshawe/S2/pytorch/Project/wikiart_classification/data/remapped_dataset\"\n",
    "dataset = load_from_disk(dataset_path)\n",
    "print(\"Remapped dataset loaded from disk\")\n",
    "print(f\"Dataset size: {len(dataset)} images.\")\n",
    "\n",
    "split_ds = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "test_dataset = split_ds[\"test\"]\n",
    "train_val_dataset = split_ds[\"train\"]\n",
    "split_remaining = train_val_dataset.train_test_split(test_size=0.125, seed=42)\n",
    "train_dataset = split_remaining[\"train\"]\n",
    "val_dataset = split_remaining[\"test\"]\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)} images\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)} images\")\n",
    "print(f\"Test dataset size: {len(test_dataset)} images\")\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandAugment(num_ops=2, magnitude=9),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def process_image(image):\n",
    "    \"\"\"\n",
    "    Receives a raw PIL image, applies the transformation, and ensures the output is 224x224.\n",
    "    \"\"\"\n",
    "    # Apply transforms. This converts the PIL image to a tensor of shape [3, 224, 224]\n",
    "    img_tensor = train_transforms(image)\n",
    "    # Double-check that the output is the desired shape\n",
    "    if img_tensor.shape[-2:] != (224, 224):\n",
    "        img_tensor = F.interpolate(img_tensor.unsqueeze(0), size=(224, 224), mode='bilinear', align_corners=False).squeeze(0)\n",
    "    return img_tensor\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate that:\n",
    "      - Processes the raw PIL image using process_image.\n",
    "      - Converts \"genre\" and \"style\" to tensors.\n",
    "    \"\"\"\n",
    "    images = [process_image(item[\"image\"]) for item in batch]\n",
    "    genres = torch.tensor([item[\"genre\"] for item in batch])\n",
    "    styles = torch.tensor([item[\"style\"] for item in batch])\n",
    "    return {\"image\": torch.stack(images), \"genre\": genres, \"style\": styles}\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=custom_collate_fn)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=32, shuffle=False, collate_fn=custom_collate_fn)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=custom_collate_fn)\n",
    "\n",
    "print(\"DataLoaders are ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ec867f-1b40-48b9-8001-a7f9d76d5711",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMultiHeadCNN(nn.Module):\n",
    "    def __init__(self, num_genres, num_styles):\n",
    "        super(SimpleMultiHeadCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 224 -> 112\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),  # 112 -> 56\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)   # 56 -> 28\n",
    "        )\n",
    "        self.flatten_dim = 128 * 28 * 28\n",
    "        self.genre_classifier = nn.Sequential(\n",
    "            nn.Linear(self.flatten_dim, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, num_genres)\n",
    "        )\n",
    "        self.style_classifier = nn.Sequential(\n",
    "            nn.Linear(self.flatten_dim, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, num_styles)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        genre_logits = self.genre_classifier(x)\n",
    "        style_logits = self.style_classifier(x)\n",
    "        return genre_logits, style_logits\n",
    "\n",
    "num_genres = len(set(dataset[\"genre\"]))\n",
    "num_styles = len(set(dataset[\"style\"]))\n",
    "print(f\"Number of genre classes: {num_genres}\")\n",
    "print(f\"Number of style classes: {num_styles}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c90ba1-7672-40e9-ba81-6f763668c489",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SimpleMultiHeadCNN(num_genres, num_styles).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43571ed-ce33-4d5c-be31-1defea1049ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "def compute_metrics(genre_logits, style_logits, genre_labels, style_labels):\n",
    "    pred_genre = torch.argmax(genre_logits, dim=1)\n",
    "    pred_style = torch.argmax(style_logits, dim=1)\n",
    "    acc_genre = (pred_genre == genre_labels).float().mean().item()\n",
    "    acc_style = (pred_style == style_labels).float().mean().item()\n",
    "    joint_acc = ((pred_genre == genre_labels) & (pred_style == style_labels)).float().mean().item()\n",
    "    return acc_genre, acc_style, joint_acc\n",
    "    \n",
    "history = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_genre_acc\": [],\n",
    "    \"train_style_acc\": [],\n",
    "    \"train_joint_acc\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_genre_acc\": [],\n",
    "    \"val_style_acc\": [],\n",
    "    \"val_joint_acc\": []\n",
    "}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc_genre = 0.0\n",
    "    train_acc_style = 0.0\n",
    "    train_joint_acc = 0.0\n",
    "    total_train = 0\n",
    "    \n",
    "    for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\", leave=False):\n",
    "        images = batch[\"image\"].to(device)\n",
    "        genre_labels = batch[\"genre\"].to(device)\n",
    "        style_labels = batch[\"style\"].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        genre_logits, style_logits = model(images)\n",
    "        loss = criterion(genre_logits, genre_labels) + criterion(style_logits, style_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_size = images.size(0)\n",
    "        train_loss += loss.item() * batch_size\n",
    "        acc_g, acc_s, joint = compute_metrics(genre_logits, style_logits, genre_labels, style_labels)\n",
    "        train_acc_genre += acc_g * batch_size\n",
    "        train_acc_style += acc_s * batch_size\n",
    "        train_joint_acc += joint * batch_size\n",
    "        total_train += batch_size\n",
    "    \n",
    "    avg_train_loss = train_loss / total_train\n",
    "    avg_train_acc_genre = train_acc_genre / total_train\n",
    "    avg_train_acc_style = train_acc_style / total_train\n",
    "    avg_train_joint_acc = train_joint_acc / total_train\n",
    "\n",
    "    history[\"train_loss\"].append(avg_train_loss)\n",
    "    history[\"train_genre_acc\"].append(avg_train_acc_genre)\n",
    "    history[\"train_style_acc\"].append(avg_train_acc_style)\n",
    "    history[\"train_joint_acc\"].append(avg_train_joint_acc)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_acc_genre = 0.0\n",
    "    val_acc_style = 0.0\n",
    "    val_joint_acc = 0.0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}\", leave=False):\n",
    "            images = batch[\"image\"].to(device)\n",
    "            genre_labels = batch[\"genre\"].to(device)\n",
    "            style_labels = batch[\"style\"].to(device)\n",
    "            \n",
    "            genre_logits, style_logits = model(images)\n",
    "            loss = criterion(genre_logits, genre_labels) + criterion(style_logits, style_labels)\n",
    "            batch_size = images.size(0)\n",
    "            val_loss += loss.item() * batch_size\n",
    "            acc_g, acc_s, joint = compute_metrics(genre_logits, style_logits, genre_labels, style_labels)\n",
    "            val_acc_genre += acc_g * batch_size\n",
    "            val_acc_style += acc_s * batch_size\n",
    "            val_joint_acc += joint * batch_size\n",
    "            total_val += batch_size\n",
    "\n",
    "    avg_val_loss = val_loss / total_val\n",
    "    avg_val_acc_genre = val_acc_genre / total_val\n",
    "    avg_val_acc_style = val_acc_style / total_val\n",
    "    avg_val_joint_acc = val_joint_acc / total_val\n",
    "\n",
    "    history[\"val_loss\"].append(avg_val_loss)\n",
    "    history[\"val_genre_acc\"].append(avg_val_acc_genre)\n",
    "    history[\"val_style_acc\"].append(avg_val_acc_style)\n",
    "    history[\"val_joint_acc\"].append(avg_val_joint_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss = {avg_train_loss:.4f}, Genre Acc = {avg_train_acc_genre:.4f}, \"\n",
    "          f\"Style Acc = {avg_train_acc_style:.4f}, Joint Acc = {avg_train_joint_acc:.4f}\")\n",
    "    print(f\"                  Val   Loss = {avg_val_loss:.4f}, Genre Acc = {avg_val_acc_genre:.4f}, \"\n",
    "          f\"Style Acc = {avg_val_acc_style:.4f}, Joint Acc = {avg_val_joint_acc:.4f}\")\n",
    "    \n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "print(\"Training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c825900-28d1-4409-9ccd-886a01c6c826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0.0\n",
    "test_acc_genre = 0.0\n",
    "test_acc_style = 0.0\n",
    "test_joint_acc = 0.0\n",
    "total_test = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Testing\", leave=False):\n",
    "        images = batch[\"image\"].to(device)\n",
    "        genre_labels = batch[\"genre\"].to(device)\n",
    "        style_labels = batch[\"style\"].to(device)\n",
    "        \n",
    "        genre_logits, style_logits = model(images)\n",
    "        loss = criterion(genre_logits, genre_labels) + criterion(style_logits, style_labels)\n",
    "        batch_size = images.size(0)\n",
    "        test_loss += loss.item() * batch_size\n",
    "        acc_g, acc_s, joint = compute_metrics(genre_logits, style_logits, genre_labels, style_labels)\n",
    "        test_acc_genre += acc_g * batch_size\n",
    "        test_acc_style += acc_s * batch_size\n",
    "        test_joint_acc += joint * batch_size\n",
    "        total_test += batch_size\n",
    "\n",
    "avg_test_loss = test_loss / total_test\n",
    "avg_test_acc_genre = test_acc_genre / total_test\n",
    "avg_test_acc_style = test_acc_style / total_test\n",
    "avg_test_joint_acc = test_joint_acc / total_test\n",
    "\n",
    "print(f\"Test Loss = {avg_test_loss:.4f}, Genre Acc = {avg_test_acc_genre:.4f}, \"\n",
    "      f\"Style Acc = {avg_test_acc_style:.4f}, Joint Acc = {avg_test_joint_acc:.4f}\")\n",
    "\n",
    "print(\"Testing complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cf1bb3f-5524-4b8b-8036-36c7a7fb448f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved.\n"
     ]
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"models_history/cnn/cnn_simple_multihhead.pth\")\n",
    "print(\"Model saved\")\n",
    "\n",
    "torch.save(history, \"models_history/cnn/cnn_training_history.pth\")\n",
    "print(\"Training history saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849bdc85-db6c-4985-8c72-e892b91ab029",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = torch.load(\"models_history/cnn/cnn_training_history.pth\")\n",
    "\n",
    "num_epochs = len(history[\"train_loss\"])\n",
    "epochs = range(1, num_epochs + 1)\n",
    "\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss\", color=\"tab:blue\")\n",
    "ax1.plot(epochs, history[\"train_loss\"], label=\"Train Loss\", color=\"tab:blue\", linestyle=\"--\")\n",
    "ax1.plot(epochs, history[\"val_loss\"], label=\"Val Loss\", color=\"tab:blue\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=\"tab:blue\")\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel(\"Accuracy\", color=\"tab:red\")\n",
    "ax2.plot(epochs, history[\"train_genre_acc\"], label=\"Train Genre Acc\", color=\"tab:red\", linestyle=\"--\")\n",
    "ax2.plot(epochs, history[\"val_genre_acc\"], label=\"Val Genre Acc\", color=\"tab:red\")\n",
    "ax2.plot(epochs, history[\"train_style_acc\"], label=\"Train Style Acc\", color=\"tab:green\", linestyle=\"--\")\n",
    "ax2.plot(epochs, history[\"val_style_acc\"], label=\"Val Style Acc\", color=\"tab:green\")\n",
    "ax2.plot(epochs, history[\"train_joint_acc\"], label=\"Train Joint Acc\", color=\"tab:purple\", linestyle=\"--\")\n",
    "ax2.plot(epochs, history[\"val_joint_acc\"], label=\"Val Joint Acc\", color=\"tab:purple\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"tab:red\")\n",
    "\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax2.legend(lines1 + lines2, labels1 + labels2, loc=\"upper center\", ncol=3)\n",
    "\n",
    "plt.title(\"Training Performance Metrics\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
