{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22056237-f4de-4b81-bb3f-dba47c4693dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_from_disk\n",
    "from tqdm.auto import tqdm\n",
    "import gc\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "import time\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2084598-578b-47ed-b930-4dbd3780a95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"C:/Users/wassi/Documents/Fanshawe/S2/pytorch/Project/wikiart_classification/models_history/resnet50_finetune/best_resnet50_finetune_multihhead.pth\"\n",
    "best_model_state = torch.load(model_path)\n",
    "config_path = \"C:/Users/wassi/Documents/Fanshawe/S2/pytorch/Project/wikiart_classification/models_history/resnet50_finetune/best_config.json\"\n",
    "\n",
    "with open(config_path, \"r\") as f:\n",
    "    best_config = json.load(f)\n",
    "\n",
    "# Data Preprocessing\n",
    "dataset_path = \"C:/Users/wassi/Documents/Fanshawe/S2/pytorch/Project/wikiart_classification/data/remapped_dataset\"\n",
    "dataset = load_from_disk(dataset_path)\n",
    "print(\"Remapped dataset loaded from disk\")\n",
    "print(f\"Dataset size: {len(dataset)} images.\")\n",
    "\n",
    "split_ds = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "test_dataset = split_ds[\"test\"]\n",
    "train_val_dataset = split_ds[\"train\"]\n",
    "split_remaining = train_val_dataset.train_test_split(test_size=0.125, seed=42)\n",
    "train_dataset = split_remaining[\"train\"]\n",
    "val_dataset = split_remaining[\"test\"]\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)} images\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)} images\")\n",
    "print(f\"Test dataset size: {len(test_dataset)} images\")\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(size=224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandAugment(num_ops=2, magnitude=9),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "def process_image(image):\n",
    "    \"\"\"Applies the transformation and ensures the output is 224x224.\"\"\"\n",
    "    img_tensor = train_transforms(image)\n",
    "    if img_tensor.shape[-2:] != (224, 224):\n",
    "        img_tensor = F.interpolate(img_tensor.unsqueeze(0), size=(224, 224), mode='bilinear', align_corners=False).squeeze(0)\n",
    "    return img_tensor\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    \"\"\"Custom collate: transforms images and converts labels to tensors.\"\"\"\n",
    "    images = [process_image(item[\"image\"]) for item in batch]\n",
    "    genres = torch.tensor([item[\"genre\"] for item in batch])\n",
    "    styles = torch.tensor([item[\"style\"] for item in batch])\n",
    "    return {\"image\": torch.stack(images), \"genre\": genres, \"style\": styles}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "class ResNet50FineTuneMultiHead(nn.Module):\n",
    "    def __init__(self, num_genres, num_styles, dropout_rate=0.0):\n",
    "        super(ResNet50FineTuneMultiHead, self).__init__()\n",
    "        # Load pretrained ResNet50\n",
    "        self.resnet = resnet50(weights=ResNet50_Weights.DEFAULT)\n",
    "        \n",
    "        # Freeze all layers first\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # Unfreeze the last 4 children modules\n",
    "        children = list(self.resnet.children())\n",
    "        for child in children[-4:]:\n",
    "            for param in child.parameters():\n",
    "                param.requires_grad = True\n",
    "        \n",
    "        # Replace the final fully connected layer with an identity to extract features\n",
    "        in_features = self.resnet.fc.in_features\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        \n",
    "        # Define new classifier heads with dropout for multi-task learning\n",
    "        self.genre_classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, num_genres) # I return raw logits! no softmax\n",
    "        )\n",
    "        \n",
    "        self.style_classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, num_styles)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.resnet(x)\n",
    "        genre_logits = self.genre_classifier(features)\n",
    "        style_logits = self.style_classifier(features)\n",
    "        return genre_logits, style_logits\n",
    "\n",
    "num_genres = len(set(dataset[\"genre\"]))\n",
    "num_styles = len(set(dataset[\"style\"]))\n",
    "print(f\"Number of genre classes: {num_genres}\")\n",
    "print(f\"Number of style classes: {num_styles}\")\n",
    "\n",
    "def compute_metrics(genre_logits, style_logits, genre_labels, style_labels):\n",
    "    \"\"\"Compute genre, style, and joint accuracy.\"\"\"\n",
    "    pred_genre = torch.argmax(genre_logits, dim=1)\n",
    "    pred_style = torch.argmax(style_logits, dim=1)\n",
    "    acc_genre = (pred_genre == genre_labels).float().mean().item()\n",
    "    acc_style = (pred_style == style_labels).float().mean().item()\n",
    "    joint_acc = ((pred_genre == genre_labels) & (pred_style == style_labels)).float().mean().item()\n",
    "    return acc_genre, acc_style, joint_acc\n",
    "    \n",
    "# Reinitialize the model\n",
    "model = ResNet50FineTuneMultiHead(num_genres, num_styles, dropout_rate=best_config[\"dropout_rate\"])\n",
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=best_config[\"batch_size\"], shuffle=False, collate_fn=custom_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f5e18a-fc80-4ff3-b510-eccc3d30bddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0.0\n",
    "test_genre_acc = 0.0\n",
    "test_style_acc = 0.0\n",
    "test_joint_acc = 0.0\n",
    "total_test = 0\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Testing\", leave=False):\n",
    "        images = batch[\"image\"]\n",
    "        genre_labels = batch[\"genre\"]\n",
    "        style_labels = batch[\"style\"]\n",
    "        \n",
    "        genre_logits, style_logits = model(images)\n",
    "        loss = criterion(genre_logits, genre_labels) + criterion(style_logits, style_labels)\n",
    "        bsize = images.size(0)\n",
    "        test_loss += loss.item() * bsize\n",
    "        tg, ts, tj = compute_metrics(genre_logits, style_logits, genre_labels, style_labels)\n",
    "        test_genre_acc += tg * bsize\n",
    "        test_style_acc += ts * bsize\n",
    "        test_joint_acc += tj * bsize\n",
    "        total_test += bsize\n",
    "\n",
    "avg_test_loss = test_loss / total_test\n",
    "avg_test_genre_acc = test_genre_acc / total_test\n",
    "avg_test_style_acc = test_style_acc / total_test\n",
    "avg_test_joint_acc = test_joint_acc / total_test\n",
    "\n",
    "print(f\"Best Model Test Loss = {avg_test_loss:.4f}\")\n",
    "print(f\"Test Genre Accuracy = {avg_test_genre_acc:.4f}, Test Style Accuracy = {avg_test_style_acc:.4f}, Test Joint Accuracy = {avg_test_joint_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0fde0c-3099-48e2-a521-53500454d0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(dataset[\"train\"][0][\"image\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
